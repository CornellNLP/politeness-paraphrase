{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to edit strategy plans in custom text\n",
    "\n",
    "This notebook demonstrates how one can obtain politeness paraphrases on custom texts. This can be done in two ways:  \n",
    "\n",
    "1. one can specify the desired strategy combinations to use for the given input \n",
    "2. alternatively, one could also specify the desired politeness level  \n",
    "\n",
    "For option 2, we will use the model trained over averaged annotator scores on the Stanford Politeness Corpus (Wikipedia portion) to estimate politeness perceptions. Note that the coefficients obtained may not accurately reflect the politeness perceptions in other communication settings.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "from collections import defaultdict\n",
    "\n",
    "from convokit import Corpus, Utterance, Speaker\n",
    "from convokit import download\n",
    "from convokit import PolitenessStrategies, TextParser\n",
    "\n",
    "# you will need to update the path of the downloaded/trained model in settings.py first\n",
    "from strategy_manipulation import remove_strategies_from_utt, add_strategies_to_utt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need spacy to help us parse the input texts, and strategy extraction is done via ConvoKit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use spacy to obtain parses for text, which the strategy extractor rely on \n",
    "spacy_nlp = spacy.load('en_core_web_sm', disable=['ner'])\n",
    "\n",
    "# we use politeness strategy collection \"politeness_local\", \n",
    "# i.e., a subset of strategies that can be achieved through localized markers   \n",
    "ps = PolitenessStrategies(strategy_attribute_name=\"strategies\", \\\n",
    "                          marker_attribute_name=\"markers\", \\\n",
    "                          strategy_collection=\"politeness_local\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Incorporating specified strategy plan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the following message as the running example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"Sorry to bother you, can you please proofread this article?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to make the following request use the strategy plan: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_plan = {\"Subjunctive\", \"For.Me\", \"Gratitude\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first identify and locate strategies currently used that are no longer part of the plan, delete the corresponding markers, and sequentially add strategies that need to be incorporated. This can be achieved as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_utterance_by_plan(message, strategy_plan, spacy_nlp, politeness_transformer):\n",
    "    \n",
    "    # importantly, we need to have markers set to be true to know the exact positions of the markers for later edits\n",
    "    utt = politeness_transformer.transform_utterance(message, markers=True)\n",
    "\n",
    "    # strategies currently used\n",
    "    strategy_set = {k for k,v in utt.meta['strategies'].items() if v == 1}\n",
    "    \n",
    "    utt.meta['strategy_set'] = strategy_plan\n",
    "    \n",
    "    # We can then determine strategies that needs to be deleted, as well as strategies that should be added, by comparing strategy_plan and strategy_set.\n",
    "    to_delete = strategy_set - strategy_plan\n",
    "    to_add = strategy_plan - strategy_set\n",
    "    \n",
    "    remove_strategies_from_utt(utt, to_delete, removed_attribute_name='context')\n",
    "    \n",
    "    return add_strategies_to_utt(utt, to_add, politeness_transformer, spacy_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'could you proofread this article for me ? thanks .'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_utterance_by_plan(message, strategy_plan, spacy_nlp, ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Paraphrasing for a target politeness level "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if one has good knowledge of the receiver's politeness perception model (we currently assume a simple linear regression model taking all local strategies as features), we can set up the ILP problem to generate the strategy combination to use, and then incorporate the strategy plan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plan_with_ilp import get_ilp_solution\n",
    "\n",
    "# load average perception model \n",
    "from settings import PERCEPTION_MODEL_PATH\n",
    "\n",
    "with open(PERCEPTION_MODEL_PATH, 'r') as f:\n",
    "    AVERAGE_MODEL = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase_utterance_by_intention(message, intended_politeness, spacy_nlp, politeness_transformer, perception_model = AVERAGE_MODEL):\n",
    "    \n",
    "    # importantly, we need to have markers set to be true to know the exact positions of the markers for later edits\n",
    "    utt = politeness_transformer.transform_utterance(message, markers=True)\n",
    "\n",
    "    # strategies currently used\n",
    "    strategy_set = {k for k,v in utt.meta['strategies'].items() if v == 1}\n",
    "    \n",
    "    utt.meta['strategy_set'] = strategy_set\n",
    "    utt.meta['intended_politeness'] = intended_politeness\n",
    "    \n",
    "    # we assume perfect channel, and use the average model to approximate receiver perception \n",
    "    strategy_plan = get_ilp_solution('0', strategy_set, perception_model, perception_model, set(), intended_politeness=intended_politeness)\n",
    "    print('Recommended strategy plan:', strategy_plan)\n",
    "    \n",
    "    to_delete = strategy_set - strategy_plan\n",
    "    to_add = strategy_plan - strategy_set\n",
    "    \n",
    "    remove_strategies_from_utt(utt, to_delete, removed_attribute_name='context')\n",
    "    \n",
    "    return add_strategies_to_utt(utt, to_add, politeness_transformer, spacy_nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then check how the message may be altered depending on the intended politeness level. (It is also worth noting that while strategies are planed out, the generation model is _not_ perfect in incorporating them.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intended politeness level = -1\n",
      "Recommended strategy plan: {'By.The.Way', 'Swearing', 'Actually', 'Indicative'}\n",
      "btw can you actually fucking proofread this article ?\n",
      "\n",
      "Intended politeness level = 0\n",
      "Recommended strategy plan: {'Please.Start', 'Indicative', 'For.Me', 'Conj.Start'}\n",
      "please can you proofread this article ?\n",
      "\n",
      "Intended politeness level = 1\n",
      "Recommended strategy plan: {'Reassurance', 'Indicative'}\n",
      "no problem . can you proofread this article ?\n",
      "\n",
      "Intended politeness level = 2\n",
      "Recommended strategy plan: {'For.You', 'Indicative', 'Greeting', 'Gratitude'}\n",
      "hi . can you proofread this article for me ? thanks .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for intended_politeness in range(-1, 3):\n",
    "    \n",
    "    print(\"Intended politeness level = {}\".format(intended_politeness))\n",
    "\n",
    "    print(paraphrase_utterance_by_intention(message, intended_politeness, spacy_nlp, ps))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convokit-test",
   "language": "python",
   "name": "convokit-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
